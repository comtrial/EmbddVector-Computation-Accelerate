

* 필요한 라이브러리 설치
$ pip install -r requirements.txt

* 실행
$ python main.py

* 검색 중 뒤에 실행 종료 될 시
$ conda install faiss-cpu -c pytorch


## Goal: 문장 파일 내에서 문장들의 유사도가 높은(0.9 이상) 문장 쌍의 추출


### 문제 접근

* 자연어의 문장 단위의 임베딩 성능을 유지하면서

* 임베딩 된 문장의 유사도 검색을 속도 측면의 성능을 최대화 하는 것


### 해결 과정

1. 벡터화 과정

* 문장 단위의 자연어 임베딩인 점을 고려하여 TF-IDF 기반의 임베딩 모델 보단 성능 면에서 뛰어난 bert 기반의 sentence-BERT 사용

* bert 를 처음 부터 모델링 할 경우 bert가 임베딩하는 차원수를 적게 하는 시도를 하였겠지만 과제의 시간을 인지 하여 사전 학습 모델 사용

* 그러므로 bert가 임베딩 하는 차원수가 768 차원이라는 점을 해결 해야 함(연산량 차원)

* TSNE, PCA 등의 모델을 사용해 보았지만 성능이 매우 좋지 않음(0.9 이상의 결과가 많음) 

* 따라서 **AutoEncoder** 를 통한 차원 축소 시도



2. 벡터화된 문장 유사도 연산

* **Autoencoder**를 차원축소를 진행하여도, 벡터화된 문장들을 연산 하는 과정에 있어 각 문장 간의 유사도 연산 시 시간 측면 성능이 좋지 않음

* 따라서 facebook 에서 공개한 벡터 유사도 라이브러리 인 **faiss** 를 사용하여 각 문장 간 indexing 된 문서에서 top-k에 대해서 만 코사인 유사도 연산



#### 결과

1. 학습된 ****Autoencoder** 를 통해 768 차원의 벡터를 20차원으로 축소시켜 연산량을 줄였습니다. 

2. **faiss** 를 활용하여 vector 연산 속도를 높였습니다.

3. 10차원으로 축소 시 **10분**, 20차원으로 축소시 **16분** 으로 연산 시간을 단축 

